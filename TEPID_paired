import os
import json

args = {}
sbatch_args = {}

configfile: "config/config.json"


if config["__default__"]["running_locally"]=="True":
    # print ("Running Locally")
    args["running_locally"] = True


else:
    print ("Running on cluster")


# cluster config


args['SAMPLES'] = glob_wildcards(config['project']['inputpath']+"/test/{S}_R1_001.fastq.gz").S
args['REFERENCE'] = config['ref']
args['TEDB'] = config['tedb']
args['SCRIPTS'] = config['tepid']['scripts']
args['REFLINE'] = config['refline']
# bash safe mode
shell.executable("/bin/bash")
#shell.prefix("set -euo pipefail; ")
#shell.prefix("source $HOME/.bashrc")

rule all:
    input:
        expand('output/align/{sample}/insertions_{sample}.bed', zip, sample=args['SAMPLES']),
        expand('output/align/{sample}/insertion_reads_{sample}.txt', zip, sample=args['SAMPLES']),
        expand('output/align/{sample}/deletions_{sample}.bed', zip, sample=args['SAMPLES']),
        expand('output/align/{sample}/deletion_reads_{sample}.txt', zip, sample=args['SAMPLES']),
        expand('output/logs/tepid_discover_log_{sample}.txt', zip, sample=args['SAMPLES'])

##### setup singularity #####

# this container defines the underlying OS for each job when using the workflow
# with --use-conda --use-singularity

singularity: "docker://continuumio/miniconda3:4.4.10"

##### setup report #####

report: "report/workflow.rst"


##### load rules #####   
include: "rules/a_yaha_bowtie_index.smk" 
include: "rules/01_tepid_map.smk"
include: "rules/02_tepid_discover.smk"

