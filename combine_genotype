import os
import json

class sampmap:
    def __init__(self,entry):
        MAPTOLANE = dict(zip(args['SAMPLES'],args['SAMPLES']))
        inv = {}
        for key, value in MAPTOLANE.items():
            MAPTOLANE[key] = value.split('_L00')[0]
        self.lane = list(MAPTOLANE.keys())
        sample = list(MAPTOLANE.values())
        for key, val in MAPTOLANE.items():
            inv[val] = inv.get(val, []) + [key]
        self.map = inv
        self.sample = set(sample)

args = {}
sbatch_args = {}

configfile: "config/config.json"


if config["__default__"]["running_locally"]=="True":
    # print ("Running Locally")
    args["running_locally"] = True


else:
    print ("Running on cluster")


# cluster config


args['SAMPLES'] = glob_wildcards(config['project']['inputpath']+"/raw/{S}_R1_001.fastq.gz").S
args['REFERENCE'] = config['ref']
args['TEDB'] = config['tedb']
args['BASEPATH'] = config['tepid']['basepath']
args['SCRIPTS'] = config['tepid']['scripts']
args['REFLINE'] = config['refline']

map_values=sampmap(args['SAMPLES'])
args['LANEDICT']=map_values.map
args['IND']=map_values.sample

print(args['LANEDICT'])
print(args['IND'])

# bash safe mode
shell.executable("/bin/bash")
#shell.prefix("set -euo pipefail; ")
#shell.prefix("source $HOME/.bashrc")


rule final_output:
  input:
    "output/merged/tepav_ins.txt",
    "output/merged/tepav_del.txt",
    "output/merged/genotyped_deletions_flipped.bed"
  


'''
rule all:
    input:
        expand("output/merged/{individual}/ambiguous_insertion_{individual}.bed",individual=args['IND']),
        expand("output/merged/{individual}/ambiguous_deletion_{individual}.bed",individual=args['IND']),
        expand("output/merged/{individual}/second_pass_insertion_{individual}.bed",individual=args['IND']),
        expand("output/merged/{individual}/second_pass_reads_insertion_{individual}.txt",individual=args['IND']),
        expand("output/merged/{individual}/second_pass_deletion_{individual}.bed",individual=args['IND']),
        expand("output/merged/{individual}/second_pass_reads_deletion_{individual}.txt",individual=args['IND'])
'''

##### setup singularity #####

# this container defines the underlying OS for each job when using the workflow
# with --use-conda --use-singularity

singularity: "docker://continuumio/miniconda3:4.4.10"

##### setup report #####

report: "report/workflow.rst"


##### load rules #####   
 
include: "rules/07_combine_bed.smk"
include: "rules/08_merge2.smk"
include: "rules/09_genotype.smk"
include: "rules/10_tepav_table.smk"
